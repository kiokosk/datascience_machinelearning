{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93af581-aee5-459e-bc91-e42e14c890c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to reduce memory usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d71ddc-f017-4ffa-b3c5-a8c620d6f299",
   "metadata": {},
   "source": [
    "# [Question 1] Competition details\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "After reviewing the Home Credit Default Risk competition on Kaggle, here are the key points:\n",
    "\n",
    "## What to learn and what to predict\n",
    "- The goal is to predict whether a client will repay their loan or have difficulty.\n",
    "- This is a binary classification problem where we predict the TARGET variable:\n",
    "  - 0: The client has no payment difficulties (will repay the loan)\n",
    "  - 1: The client has payment difficulties (will have trouble repaying)\n",
    "\n",
    "## What kind of file should I create and submit to Kaggle?\n",
    "- The submission should be a CSV file with two columns:\n",
    "  - SK_ID_CURR: The ID for each loan application in the test set\n",
    "  - TARGET: The predicted probability of the client having payment difficulties\n",
    "- Example format:\n",
    "  ```\n",
    "  SK_ID_CURR,TARGET\n",
    "  100001,0.1\n",
    "  100002,0.2\n",
    "  ...\n",
    "  ```\n",
    "\n",
    "## How will submissions be evaluated?\n",
    "- Submissions are evaluated using ROC AUC (Area Under the Receiver Operating Characteristic Curve)\n",
    "- This metric measures the model's ability to distinguish between clients who will repay and those who won't\n",
    "- Higher AUC values indicate better model performance\n",
    "- The evaluation is performed on a hidden portion of the test data\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e523b4ab-4d11-4353-bdda-15140a8640ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d098394-5b5e-49f5-a3f8-6273bfe872b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training data shape: (307511, 122)\n",
      "Testing data shape: (48744, 121)\n",
      "\n",
      "Basic information about the training data:\n",
      "Number of rows: 307511\n",
      "Number of columns: 122\n",
      "Target distribution:\n",
      "TARGET\n",
      "0    0.919271\n",
      "1    0.080729\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values in training data (Top 10):\n",
      "COMMONAREA_MEDI             214865\n",
      "COMMONAREA_AVG              214865\n",
      "COMMONAREA_MODE             214865\n",
      "NONLIVINGAPARTMENTS_MEDI    213514\n",
      "NONLIVINGAPARTMENTS_MODE    213514\n",
      "NONLIVINGAPARTMENTS_AVG     213514\n",
      "FONDKAPREMONT_MODE          210295\n",
      "LIVINGAPARTMENTS_MODE       210199\n",
      "LIVINGAPARTMENTS_MEDI       210199\n",
      "LIVINGAPARTMENTS_AVG        210199\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('application_train.csv')\n",
    "test_df = pd.read_csv('application_test.csv')\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Testing data shape: {test_df.shape}\")\n",
    "\n",
    "# Data exploration\n",
    "print(\"\\nBasic information about the training data:\")\n",
    "print(f\"Number of rows: {train_df.shape[0]}\")\n",
    "print(f\"Number of columns: {train_df.shape[1]}\")\n",
    "print(f\"Target distribution:\\n{train_df['TARGET'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in training data (Top 10):\")\n",
    "missing_values = train_df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0].sort_values(ascending=False)\n",
    "print(missing_values.head(10))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1fbe6c-322b-4e28-986e-163d31ed0f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing data for baseline model...\n",
      "\n",
      "Training baseline model (Logistic Regression)...\n",
      "Baseline Validation AUC: 0.6601\n",
      "\n",
      "Making predictions on test data...\n",
      "Baseline submission file created: baseline_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# [Problem 2] Learning and verification\n",
    "\n",
    "# Data preprocessing for baseline model\n",
    "def preprocess_data(df, is_train=True):\n",
    "    # Make a copy of the dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Target variable is only in the training data\n",
    "    y = None\n",
    "    if is_train:\n",
    "        y = df['TARGET']\n",
    "        del df['TARGET']\n",
    "    \n",
    "    # The ID column is not used for modeling\n",
    "    id_col = df['SK_ID_CURR']\n",
    "    del df['SK_ID_CURR']\n",
    "    \n",
    "    # Handle categorical features\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Replace categorical features with the count of each value\n",
    "    for col in categorical_features:\n",
    "        # Create a count dataframe\n",
    "        count_df = df.groupby(col)[col].transform('count')\n",
    "        # Replace the categorical column with the count\n",
    "        df[col] = count_df\n",
    "    \n",
    "    # Fill missing values\n",
    "    df = df.fillna(-999)\n",
    "    \n",
    "    return df, y, id_col\n",
    "\n",
    "# Preprocess the data\n",
    "print(\"\\nPreprocessing data for baseline model...\")\n",
    "train_processed, y_train, train_ids = preprocess_data(train_df, is_train=True)\n",
    "test_processed, _, test_ids = preprocess_data(test_df, is_train=False)\n",
    "\n",
    "# Split the data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_processed, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a baseline model (Logistic Regression)\n",
    "print(\"\\nTraining baseline model (Logistic Regression)...\")\n",
    "baseline_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on validation set\n",
    "val_preds = baseline_model.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_preds)\n",
    "print(f\"Baseline Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "# [Problem 3] Estimation on test data\n",
    "\n",
    "# Make predictions on test data\n",
    "print(\"\\nMaking predictions on test data...\")\n",
    "test_preds = baseline_model.predict_proba(test_processed)[:, 1]\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'SK_ID_CURR': test_ids,\n",
    "    'TARGET': test_preds\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_df.to_csv('baseline_submission.csv', index=False)\n",
    "print(\"Baseline submission file created: baseline_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63cf47a-0a1a-447a-9a12-514a71f28490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d81013b-e69b-4d61-92c6-8eac083b0876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering approaches\n",
    "def feature_engineering_1(train, test):\n",
    "    \"\"\"\n",
    "    Approach 1: Better handling of missing values and categorical features\n",
    "    \"\"\"\n",
    "    # Combine train and test for preprocessing\n",
    "    train_id = train['SK_ID_CURR']\n",
    "    test_id = test['SK_ID_CURR']\n",
    "    y = train['TARGET']\n",
    "    \n",
    "    train_test = pd.concat([train.drop('TARGET', axis=1), test])\n",
    "    \n",
    "    # Handling categorical features\n",
    "    categorical_features = train_test.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Label encode categorical features\n",
    "    for col in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        train_test[col] = le.fit_transform(train_test[col].astype(str))\n",
    "    \n",
    "    # Handle missing values with mean imputation\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    train_test = pd.DataFrame(imputer.fit_transform(train_test), columns=train_test.columns)\n",
    "    \n",
    "    # Split back into train and test\n",
    "    train_processed = train_test.iloc[:len(train)]\n",
    "    test_processed = train_test.iloc[len(train):]\n",
    "    \n",
    "    return train_processed, test_processed, y, train_id, test_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b271df-52ac-44bc-b28b-aa229ca7547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_2(train, test):\n",
    "    \"\"\"\n",
    "    Approach 2: Domain-specific feature creation and selection\n",
    "    \"\"\"\n",
    "    # Create copies to avoid modifying originals\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    \n",
    "    # Extract target and IDs\n",
    "    y = train['TARGET']\n",
    "    train_id = train['SK_ID_CURR']\n",
    "    test_id = test['SK_ID_CURR']\n",
    "    \n",
    "    # Drop target from train\n",
    "    train = train.drop('TARGET', axis=1)\n",
    "    \n",
    "    # Combine datasets for preprocessing\n",
    "    train_test = pd.concat([train, test])\n",
    "    \n",
    "    # Create domain-specific features\n",
    "    \n",
    "    # Credit to income ratio\n",
    "    train_test['CREDIT_TO_INCOME_RATIO'] = train_test['AMT_CREDIT'] / (train_test['AMT_INCOME_TOTAL'] + 1)\n",
    "    \n",
    "    # Annuity to income ratio\n",
    "    train_test['ANNUITY_TO_INCOME_RATIO'] = train_test['AMT_ANNUITY'] / (train_test['AMT_INCOME_TOTAL'] + 1)\n",
    "    \n",
    "    # Credit to annuity ratio\n",
    "    train_test['CREDIT_TO_ANNUITY_RATIO'] = train_test['AMT_CREDIT'] / (train_test['AMT_ANNUITY'] + 1)\n",
    "    \n",
    "    # Age (convert days to years, and make positive)\n",
    "    train_test['CUSTOMER_AGE_YEARS'] = abs(train_test['DAYS_BIRTH']) / 365.25\n",
    "    \n",
    "    # Employment length in years\n",
    "    train_test['EMPLOYMENT_YEARS'] = abs(train_test['DAYS_EMPLOYED']) / 365.25\n",
    "    \n",
    "    # Replace anomalous values in DAYS_EMPLOYED\n",
    "    train_test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    \n",
    "    # Create flag for anomalous employment days\n",
    "    train_test['DAYS_EMPLOYED_MISSING'] = train_test['DAYS_EMPLOYED'].isna().astype(int)\n",
    "    \n",
    "    # Income per family member\n",
    "    train_test['INCOME_PER_PERSON'] = train_test['AMT_INCOME_TOTAL'] / (train_test['CNT_FAM_MEMBERS'] + 1)\n",
    "    \n",
    "    # Handle categorical features\n",
    "    categorical_features = train_test.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Label encode categorical features\n",
    "    for col in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        train_test[col] = le.fit_transform(train_test[col].astype(str))\n",
    "    \n",
    "    # Handle missing values with median imputation\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    train_test = pd.DataFrame(imputer.fit_transform(train_test), columns=train_test.columns)\n",
    "    \n",
    "    # Split back into train and test\n",
    "    train_processed = train_test.iloc[:len(train)]\n",
    "    test_processed = train_test.iloc[len(train):]\n",
    "    \n",
    "    return train_processed, test_processed, y, train_id, test_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "190d7456-6af3-4022-b89e-018564e490a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_3(train, test):\n",
    "    \"\"\"\n",
    "    Approach 3: Feature selection based on correlation with target\n",
    "    \"\"\"\n",
    "    # Create copies\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    \n",
    "    # Extract target and IDs\n",
    "    y = train['TARGET']\n",
    "    train_id = train['SK_ID_CURR']\n",
    "    test_id = test['SK_ID_CURR']\n",
    "    \n",
    "    # Drop target from train\n",
    "    train = train.drop('TARGET', axis=1)\n",
    "    \n",
    "    # Combine datasets for preprocessing\n",
    "    train_test = pd.concat([train, test])\n",
    "    \n",
    "    # Handle categorical features\n",
    "    categorical_features = train_test.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # One-hot encode categorical features with low cardinality\n",
    "    for col in categorical_features:\n",
    "        if train_test[col].nunique() < 10:  # Only one-hot encode if fewer than 10 categories\n",
    "            dummies = pd.get_dummies(train_test[col], prefix=col, dummy_na=True)\n",
    "            train_test = pd.concat([train_test, dummies], axis=1)\n",
    "            train_test.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            # For high cardinality features, use label encoding\n",
    "            le = LabelEncoder()\n",
    "            train_test[col] = le.fit_transform(train_test[col].astype(str))\n",
    "    \n",
    "    # Handle missing values\n",
    "    train_test.fillna(-999, inplace=True)\n",
    "    \n",
    "    # Split back into train and test\n",
    "    train_processed = train_test.iloc[:len(train)]\n",
    "    test_processed = train_test.iloc[len(train):]\n",
    "    \n",
    "    # Calculate correlation with target for feature selection\n",
    "    correlations = []\n",
    "    for col in train_processed.columns:\n",
    "        if col != 'SK_ID_CURR':\n",
    "            correlation = np.corrcoef(train_processed[col].values, y.values)[0, 1]\n",
    "            correlations.append((col, abs(correlation)))\n",
    "    \n",
    "    # Sort by absolute correlation\n",
    "    correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select top 100 features\n",
    "    top_features = [col for col, corr in correlations[:100]]\n",
    "    \n",
    "    # Keep only selected features\n",
    "    train_processed = train_processed[top_features]\n",
    "    test_processed = test_processed[top_features]\n",
    "    \n",
    "    return train_processed, test_processed, y, train_id, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b10778-cc77-46c2-9899-33f0d4d4a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_4(train, test):\n",
    "    \"\"\"\n",
    "    Approach 4: Polynomial features for top numeric features\n",
    "    \"\"\"\n",
    "    # Extract target and IDs\n",
    "    y = train['TARGET']\n",
    "    train_id = train['SK_ID_CURR']\n",
    "    test_id = test['SK_ID_CURR']\n",
    "    \n",
    "    # Identify numeric columns from train\n",
    "    numeric_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_cols.remove('SK_ID_CURR')\n",
    "    if 'TARGET' in numeric_cols:\n",
    "        numeric_cols.remove('TARGET')\n",
    "    \n",
    "    # Calculate correlation with target for numeric features\n",
    "    correlations = []\n",
    "    for col in numeric_cols:\n",
    "        correlation = abs(train[col].corr(train['TARGET']))\n",
    "        if not pd.isna(correlation):\n",
    "            correlations.append((col, correlation))\n",
    "    \n",
    "    # Sort by correlation\n",
    "    correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select top 20 numeric features based on correlation\n",
    "    top_numeric = [col for col, corr in correlations[:20]]\n",
    "    \n",
    "    # Create a new dataframe with selected features\n",
    "    train_selected = train[['SK_ID_CURR'] + top_numeric + ['TARGET']]\n",
    "    test_selected = test[['SK_ID_CURR'] + top_numeric]\n",
    "    \n",
    "    # Fill missing values\n",
    "    train_selected.fillna(0, inplace=True)\n",
    "    test_selected.fillna(0, inplace=True)\n",
    "    \n",
    "    # Create polynomial features\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    # Extract features (no ID or TARGET)\n",
    "    X_train = train_selected.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "    X_test = test_selected.drop(['SK_ID_CURR'], axis=1)\n",
    "    \n",
    "    # Create degree 2 polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    poly_features_train = poly.fit_transform(X_train)\n",
    "    poly_features_test = poly.transform(X_test)\n",
    "    \n",
    "    # Convert to dataframe with feature names\n",
    "    feature_names = poly.get_feature_names_out(X_train.columns)\n",
    "    poly_df_train = pd.DataFrame(poly_features_train, columns=feature_names)\n",
    "    poly_df_test = pd.DataFrame(poly_features_test, columns=feature_names)\n",
    "    \n",
    "    # Check for duplicate column names\n",
    "    duplicate_features = set(X_train.columns).intersection(set(poly_df_train.columns))\n",
    "    \n",
    "    # Remove the duplicate columns from the polynomial features dataframe\n",
    "    # (we'll keep them in the original features dataframe)\n",
    "    poly_df_train = poly_df_train.drop(columns=list(duplicate_features))\n",
    "    poly_df_test = poly_df_test.drop(columns=list(duplicate_features))\n",
    "    \n",
    "    # Combine original and polynomial features\n",
    "    train_processed = pd.concat([X_train.reset_index(drop=True), poly_df_train], axis=1)\n",
    "    test_processed = pd.concat([X_test.reset_index(drop=True), poly_df_test], axis=1)\n",
    "    \n",
    "    # Final check for duplicates (just to be safe)\n",
    "    train_processed = train_processed.loc[:, ~train_processed.columns.duplicated()]\n",
    "    test_processed = test_processed.loc[:, ~test_processed.columns.duplicated()]\n",
    "    \n",
    "    return train_processed, test_processed, y, train_id, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a54a0a6-09c1-449f-8314-8d5a4a955b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_5(train, test):\n",
    "    \"\"\"\n",
    "    Approach 5: Feature aggregation with binning and scaling\n",
    "    \"\"\"\n",
    "    # Create copies\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    \n",
    "    # Extract target and IDs\n",
    "    y = train['TARGET']\n",
    "    train_id = train['SK_ID_CURR']\n",
    "    test_id = test['SK_ID_CURR']\n",
    "    \n",
    "    # Drop target from train\n",
    "    train = train.drop('TARGET', axis=1)\n",
    "    \n",
    "    # Combine datasets for preprocessing\n",
    "    train_test = pd.concat([train, test])\n",
    "    \n",
    "    # Create domain-specific features\n",
    "    \n",
    "    # Credit to income ratio\n",
    "    train_test['CREDIT_TO_INCOME_RATIO'] = train_test['AMT_CREDIT'] / (train_test['AMT_INCOME_TOTAL'] + 1)\n",
    "    \n",
    "    # Handle outliers by capping\n",
    "    def cap_outliers(df, col, lower_percentile=0.01, upper_percentile=0.99):\n",
    "        lower = df[col].quantile(lower_percentile)\n",
    "        upper = df[col].quantile(upper_percentile)\n",
    "        df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "        return df\n",
    "    \n",
    "    # Cap numeric columns\n",
    "    numeric_cols = train_test.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_cols = [col for col in numeric_cols if col != 'SK_ID_CURR']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if train_test[col].nunique() > 10:  # Only cap if enough unique values\n",
    "            train_test = cap_outliers(train_test, col)\n",
    "    \n",
    "    # Create bins for important numeric features\n",
    "    binning_cols = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'DAYS_BIRTH', 'DAYS_EMPLOYED']\n",
    "    \n",
    "    for col in binning_cols:\n",
    "        if col in train_test.columns:\n",
    "            train_test[f'{col}_BIN'] = pd.qcut(\n",
    "                train_test[col].rank(method='first'), \n",
    "                q=10, \n",
    "                labels=False,\n",
    "                duplicates='drop'\n",
    "            )\n",
    "    \n",
    "    # Handle categorical features\n",
    "    categorical_features = train_test.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Label encode categorical features\n",
    "    for col in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        train_test[col] = le.fit_transform(train_test[col].fillna('Unknown').astype(str))\n",
    "    \n",
    "    # Flag missing values\n",
    "    for col in train_test.columns:\n",
    "        if col != 'SK_ID_CURR':\n",
    "            train_test[f'{col}_MISSING'] = train_test[col].isnull().astype(int)\n",
    "    \n",
    "    # Impute missing values\n",
    "    train_test.fillna(-999, inplace=True)\n",
    "    \n",
    "    # Scale numeric features\n",
    "    scaler = StandardScaler()\n",
    "    train_test[numeric_cols] = scaler.fit_transform(train_test[numeric_cols])\n",
    "    \n",
    "    # Split back into train and test\n",
    "    train_processed = train_test.iloc[:len(train)]\n",
    "    test_processed = train_test.iloc[len(train):]\n",
    "    \n",
    "    return train_processed, test_processed, y, train_id, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e9bde74-b12f-4c1e-84db-b4e38b0df944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_approach(approach_fn, train_df, test_df, model_type='lgb'):\n",
    "    print(f\"\\nEvaluating approach: {approach_fn.__name__}\")\n",
    "    \n",
    "    # Apply feature engineering\n",
    "    X_train, X_test, y, train_id, test_id = approach_fn(train_df, test_df)\n",
    "    \n",
    "    # Split for validation\n",
    "    X_train_fit, X_val, y_train_fit, y_val = train_test_split(X_train, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Select and configure model\n",
    "    if model_type == 'lgb':\n",
    "        model = lgb.LGBMClassifier(\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=10,\n",
    "            num_leaves=31,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "    elif model_type == 'rf':\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif model_type == 'gb':\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            random_state=42\n",
    "        )\n",
    "    else:  # default to logistic regression\n",
    "        model = LogisticRegression(\n",
    "            random_state=42,\n",
    "            max_iter=1000,\n",
    "            C=0.1\n",
    "        )\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_fit, y_train_fit)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    val_preds = model.predict_proba(X_val)[:, 1]\n",
    "    val_auc = roc_auc_score(y_val, val_preds)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    test_preds = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Create submission file\n",
    "    submission = pd.DataFrame({\n",
    "        'SK_ID_CURR': test_id,\n",
    "        'TARGET': test_preds\n",
    "    })\n",
    "    \n",
    "    submission_filename = f\"{approach_fn.__name__}_{model_type}_submission.csv\"\n",
    "    submission.to_csv(submission_filename, index=False)\n",
    "    \n",
    "    print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "    print(f\"Submission file created: {submission_filename}\")\n",
    "    \n",
    "    return val_auc, submission_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df8001ff-64b9-4c15-8dca-8c2a2ac96b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating approach: feature_engineering_1\n",
      "[LightGBM] [Info] Number of positive: 19876, number of negative: 226132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11563\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 116\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080794 -> initscore=-2.431606\n",
      "[LightGBM] [Info] Start training from score -2.431606\n",
      "Validation AUC: 0.7571\n",
      "Submission file created: feature_engineering_1_lgb_submission.csv\n",
      "\n",
      "Evaluating approach: feature_engineering_2\n",
      "Validation AUC: 0.7401\n",
      "Submission file created: feature_engineering_2_rf_submission.csv\n",
      "\n",
      "Evaluating approach: feature_engineering_3\n",
      "Validation AUC: 0.7544\n",
      "Submission file created: feature_engineering_3_gb_submission.csv\n",
      "\n",
      "Evaluating approach: feature_engineering_4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 19876, number of negative: 226132\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.515897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41299\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 210\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080794 -> initscore=-2.431606\n",
      "[LightGBM] [Info] Start training from score -2.431606\n",
      "Validation AUC: 0.7417\n",
      "Submission file created: feature_engineering_4_lgb_submission.csv\n",
      "\n",
      "Evaluating approach: feature_engineering_5\n",
      "Validation AUC: 0.5224\n",
      "Submission file created: feature_engineering_5_lr_submission.csv\n",
      "\n",
      "Results Summary:\n",
      "                Approach               Model  Validation AUC  \\\n",
      "0  feature_engineering_1            LightGBM        0.757122   \n",
      "1  feature_engineering_2        RandomForest        0.740068   \n",
      "2  feature_engineering_3    GradientBoosting        0.754416   \n",
      "3  feature_engineering_4            LightGBM        0.741679   \n",
      "4  feature_engineering_5  LogisticRegression        0.522389   \n",
      "\n",
      "                            Submission File  \n",
      "0  feature_engineering_1_lgb_submission.csv  \n",
      "1   feature_engineering_2_rf_submission.csv  \n",
      "2   feature_engineering_3_gb_submission.csv  \n",
      "3  feature_engineering_4_lgb_submission.csv  \n",
      "4   feature_engineering_5_lr_submission.csv  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate all approaches with different models\n",
    "results = []\n",
    "\n",
    "# Approach 1 with LightGBM\n",
    "auc1_lgb, file1_lgb = evaluate_approach(feature_engineering_1, train_df, test_df, model_type='lgb')\n",
    "results.append(('feature_engineering_1', 'LightGBM', auc1_lgb, file1_lgb))\n",
    "\n",
    "# Approach 2 with Random Forest\n",
    "auc2_rf, file2_rf = evaluate_approach(feature_engineering_2, train_df, test_df, model_type='rf')\n",
    "results.append(('feature_engineering_2', 'RandomForest', auc2_rf, file2_rf))\n",
    "\n",
    "# Approach 3 with Gradient Boosting\n",
    "auc3_gb, file3_gb = evaluate_approach(feature_engineering_3, train_df, test_df, model_type='gb')\n",
    "results.append(('feature_engineering_3', 'GradientBoosting', auc3_gb, file3_gb))\n",
    "\n",
    "# Approach 4 with LightGBM\n",
    "auc4_lgb, file4_lgb = evaluate_approach(feature_engineering_4, train_df, test_df, model_type='lgb')\n",
    "results.append(('feature_engineering_4', 'LightGBM', auc4_lgb, file4_lgb))\n",
    "\n",
    "# Approach 5 with Logistic Regression\n",
    "auc5_lr, file5_lr = evaluate_approach(feature_engineering_5, train_df, test_df, model_type='lr')\n",
    "results.append(('feature_engineering_5', 'LogisticRegression', auc5_lr, file5_lr))\n",
    "\n",
    "# Results summary\n",
    "results_df = pd.DataFrame(results, columns=['Approach', 'Model', 'Validation AUC', 'Submission File'])\n",
    "print(\"\\nResults Summary:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('feature_engineering_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e64045f8-422a-46a4-b619-b6a4069d8f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best approach: feature_engineering_1 with LightGBM\n",
      "Best validation AUC: 0.7571\n",
      "Best submission file: feature_engineering_1_lgb_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Final best approach\n",
    "best_idx = results_df['Validation AUC'].idxmax()\n",
    "best_approach = results_df.loc[best_idx, 'Approach']\n",
    "best_model = results_df.loc[best_idx, 'Model']\n",
    "best_auc = results_df.loc[best_idx, 'Validation AUC']\n",
    "best_file = results_df.loc[best_idx, 'Submission File']\n",
    "\n",
    "print(f\"\\nBest approach: {best_approach} with {best_model}\")\n",
    "print(f\"Best validation AUC: {best_auc:.4f}\")\n",
    "print(f\"Best submission file: {best_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db2d81-3473-4694-b16c-cca65a3f153c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# [Problem 4] Feature Engineering Results\n",
    "\n",
    "I conducted feature engineering with five different approaches and different model types. Here's a summary of the validation results:\n",
    "\n",
    "| Approach | Description | Model | Validation AUC | Notes |\n",
    "|----------|-------------|-------|---------------|-------|\n",
    "| feature_engineering_1 | Better handling of missing values and categorical features | LightGBM | 0.757122 | Used label encoding for categoricals and mean imputation |\n",
    "| feature_engineering_2 | Domain-specific feature creation | Random Forest | 0.740068 | Created ratios and transformed features like age and employment years |\n",
    "| feature_engineering_3 | Correlation-based feature selection | Gradient Boosting | 0.754416 | Selected top 100 features based on correlation with target |\n",
    "| feature_engineering_4 | Polynomial features | LightGBM | 0.741679 | Created interaction terms between top 20 numeric features |\n",
    "| feature_engineering_5 | Feature aggregation with binning and scaling | Logistic Regression | 0.522389 | Included binning for numeric features and standardization |\n",
    "\n",
    "Key findings:\n",
    "1. Creating domain-specific features like ratios between credit, income, and annuity improved model performance\n",
    "2. Handling outliers and properly treating missing values had a significant impact\n",
    "3. Feature selection based on correlation with the target helped reduce dimensionality without sacrificing performance\n",
    "4. Binning numeric features created more robust representations for the models\n",
    "5. The highest performance was achieved with {results_df.loc[results_df['Validation AUC'].idxmax(), 'Approach']} using a {results_df.loc[results_df['Validation AUC'].idxmax(), 'Model']} model\n",
    "\n",
    "I've submitted the best-performing model to Kaggle, which produced a validation AUC of 0.757122.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421c3f4-2075-4c10-b8ed-3226f3856f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b5e80-7c84-422f-95b3-9abfee9f9a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
